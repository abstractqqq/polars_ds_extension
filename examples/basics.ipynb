{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529f4422-5c3a-4bd6-abe0-a15edfc62abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars_ds as pds\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a314316",
   "metadata": {},
   "source": [
    "# This notebook illustrates the basic usage of this package\n",
    "\n",
    "You need to create an environment with this package installed to run this notebook. (usually latest version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aef5c69-fff3-4779-9b58-f939d725f0b0",
   "metadata": {},
   "source": [
    "# Num Extensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430fec01-5d0b-422f-b099-c86037512b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 10_000\n",
    "df = (\n",
    "    pl.DataFrame(\n",
    "        {\n",
    "            \"f\": np.sin(list(range(size))),\n",
    "            \"time_idx\": range(size),\n",
    "            \"dummy\": [\"a\"] * (size // 2) + [\"b\"] * (size // 2),\n",
    "            \"actual\": np.round(np.random.random(size=size)).astype(np.int32),\n",
    "            \"predicted\": np.random.random(size=size),\n",
    "            \"dummy_groups\": [\"a\"] * (size // 2) + [\"b\"] * (size // 2),\n",
    "        }\n",
    "    )\n",
    "    .with_columns(\n",
    "        pds.random(0.0, 1.0).alias(\"x1\"),\n",
    "        pds.random(0.0, 1.0).alias(\"x2\"),\n",
    "        pds.random(0.0, 1.0).alias(\"x3\"),\n",
    "        pds.random(0.0, 1.0).alias(\"a\"),\n",
    "        pds.random(0.0, 1.0).alias(\"b\"),\n",
    "    )\n",
    "    .with_columns(\n",
    "        y=pl.col(\"x1\") * 0.15 + pl.col(\"x2\") * 0.3 - pl.col(\"x3\") * 1.5 + pds.random() * 0.0001,\n",
    "        y2=pl.col(\"x1\") * 0.13 + pl.col(\"x2\") * 0.45 - pl.col(\"x3\") * 0.1 + pds.random() * 0.0001,\n",
    "    )\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f98453-34cd-4afc-b35d-db58fa60a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column-wise Jaccard Similarity. Result should be 0 as they are distinct\n",
    "df.select(pds.jaccard_col(\"x1\", pl.col(\"x2\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416d5346-e75b-4769-a953-e898d6a4d84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT. First is real part, second is complex part\n",
    "# By default, this behaves the same as np's rfft, which returns a non-redundant\n",
    "# compact representation of fft output.\n",
    "df.select(pds.rfft(\"f\")).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c76353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFT. But return the full length\n",
    "df.select(pds.rfft(\"f\", return_full=True)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6662d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple Convolutions at once\n",
    "# Modes: `same`, `left` (left-aligned same), `right` (right-aligned same), `valid` or `full`\n",
    "# Method: `fft`, `direct`\n",
    "# Currently slower than SciPy but provides parallelism because of Polars\n",
    "df.select(\n",
    "    pds.convolve(\n",
    "        \"f\", [-1, 0, 0, 0, 1], mode=\"full\", method=\"fft\"\n",
    "    ),  # column f with the kernel given here\n",
    "    pds.convolve(\"a\", [-1, 0, 0, 0, 1], mode=\"full\", method=\"direct\"),\n",
    "    pds.convolve(\"b\", [-1, 0, 0, 0, 1], mode=\"full\", method=\"direct\"),\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed47b643-6bcc-43f6-9a25-82168c33e7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "df.select(pds.lin_reg(pl.col(\"x1\"), pl.col(\"x2\"), target=pl.col(\"y\"), add_bias=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94324b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression, multi-target\n",
    "df.select(\n",
    "    pds.lin_reg(pl.col(\"x1\"), pl.col(\"x2\"), target=[pl.col(\"y\"), pl.col(\"y2\")], add_bias=False)\n",
    ").unnest(\"coeffs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6613a769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want the underlying calculation to be done in f32 instead of f64, you may use the following.\n",
    "# In some cases, f32 can run faster, especially when input data is in f32.\n",
    "pds.config.LIN_REG_EXPR_F64 = False\n",
    "df.select(\n",
    "    pds.lin_reg(pl.col(\"x1\"), pl.col(\"x2\"), target=[pl.col(\"y\"), pl.col(\"y2\")], add_bias=False)\n",
    ").unnest(\"coeffs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f45035",
   "metadata": {},
   "outputs": [],
   "source": [
    "pds.Config.LIN_REG_EXPR_F64 = True  # pds.Config or pds.config will both work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6da23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    pds.lin_reg_report(\n",
    "        # formulaic input is also available for lstsq related queries,\n",
    "        # or you can always use polars expressions, e.g. pl.col('x1') + 1, pl.col('x2').exp(), pl.col('x3').sin()\n",
    "        \"ln(x1+1)\",\n",
    "        \"exp(x2)\",\n",
    "        \"sin(x3)\",\n",
    "        target=\"y\",\n",
    "        add_bias=True,\n",
    "    ).alias(\"report\")\n",
    ").unnest(\"report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae6021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pds.config.LIN_REG_EXPR_F64 = False\n",
    "df.select(\n",
    "    pds.lin_reg_report(\n",
    "        # formulaic input is also available for lstsq related queries,\n",
    "        # or you can always use polars expressions, e.g. pl.col('x1') + 1, pl.col('x2').exp(), pl.col('x3').sin()\n",
    "        \"ln(x1+1)\",\n",
    "        \"exp(x2)\",\n",
    "        \"sin(x3)\",\n",
    "        target=\"y\",\n",
    "        add_bias=True,\n",
    "    ).alias(\"report\")\n",
    ").unnest(\"report\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d9451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pds.config.LIN_REG_EXPR_F64 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16511624-fc7f-45fc-b28e-ad9a91c1bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    \"dummy\",\n",
    "    pds.lin_reg(pl.col(\"x1\"), pl.col(\"x2\"), target=pl.col(\"y\"), add_bias=False).over(\n",
    "        pl.col(\"dummy\")\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f550c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want prediction and residue instead of coefficients\n",
    "df.select(\n",
    "    \"x1\",\n",
    "    \"x2\",\n",
    "    \"y\",\n",
    "    pds.lin_reg(\"x1\", pl.col(\"x2\"), target=\"y\", add_bias=False, return_pred=True).alias(\n",
    "        \"prediction\"\n",
    "    ),\n",
    ").unnest(\"prediction\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9fb061-340d-423d-9107-772387006ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group_by(\"dummy\").agg(\n",
    "    pds.lin_reg(pl.col(\"x1\"), pl.col(\"x2\"), target=pl.col(\"y\"), add_bias=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955f2db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "df.group_by(\"dummy\").agg(\n",
    "    pds.lin_reg(pl.col(\"x1\"), pl.col(\"x2\"), target=pl.col(\"y\"), l1_reg=0.1, add_bias=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdae8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# R2 metric of lasso regressions on each group\n",
    "df.group_by(\"dummy\").agg(\n",
    "    pds.query_r2(\n",
    "        actual=pl.col(\"y\"),\n",
    "        pred=pds.lin_reg(\n",
    "            pl.col(\"x1\"),\n",
    "            pl.col(\"x2\"),\n",
    "            target=pl.col(\"y\"),\n",
    "            l1_reg=0.1,\n",
    "            return_pred=True,\n",
    "            add_bias=False,\n",
    "        ).struct.field(\"pred\"),\n",
    "    ).alias(\"lasso_r2\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ff27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling regression\n",
    "df.select(\n",
    "    \"y\",\n",
    "    \"x1\",\n",
    "    \"x2\",\n",
    "    pds.rolling_lin_reg(\"x1\", \"x2\", target=\"y\", window_size=5, null_policy=\"zero\").alias(\"result\"),\n",
    ").unnest(\"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fda8ca-57e7-4e02-a3f0-283ecce66a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditional Entropy, should be 0 because x1 is an ID\n",
    "df.select(pds.query_cond_entropy(\"y\", \"x1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81def1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only want singular values (principal values?)\n",
    "df.select(pds.singular_values(\"a\", \"b\", \"x1\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc497383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Singular values + The principal components\n",
    "df.select(pds.pca(\"a\", \"b\")).unnest(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e047d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PC1\n",
    "df.select(pds.principal_components(\"a\", \"b\", k=1).alias(\"principal_components\")).unnest(\n",
    "    \"principal_components\"\n",
    ").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2e036f",
   "metadata": {},
   "source": [
    "# ML Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d0d094-3c4c-4230-a589-1027c5690162",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.group_by(\"dummy_groups\").agg(\n",
    "    pds.query_l2(\"actual\", \"predicted\").alias(\"l2\"),\n",
    "    pds.query_log_loss(\"actual\", \"predicted\").alias(\"log loss\"),\n",
    "    pds.query_binary_metrics(actual=\"actual\", pred=\"predicted\").alias(\"combo\"),\n",
    ").unnest(\"combo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859391b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8d7c6e3-0f1d-45f0-9fdb-cdb303b98556",
   "metadata": {},
   "source": [
    "# Str Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad36f9-264e-4a49-bf36-936639440edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 100_000\n",
    "df2 = pl.DataFrame(\n",
    "    {\"sen\": [\"Hello, world! I'm going to church.\"] * size, \"word\": [\"words\", \"word\"] * (size // 2)}\n",
    ")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69237c02-5f9f-4e92-b68d-6ac43aad1a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.select(pds.str_leven(\"word\", pl.lit(\"world\"))).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eba320c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Damerau-Levenshtein\n",
    "df2.select(pds.str_d_leven(\"word\", pl.lit(\"world\"))).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "795396dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.select(  # column \"word\" vs. the word \"world\"\n",
    "    pds.str_leven(\"word\", pl.lit(\"world\"), return_sim=True)\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dad7633-67fa-47f3-b86a-9f4cd097a650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.filter(\n",
    "    # This is way faster than computing ditance and then doing a filter\n",
    "    pds.filter_by_levenshtein(pl.col(\"word\"), pl.lit(\"world\"), 1)  # <= 1.\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9477c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"word\": [\"apple\", \"banana\", \"pineapple\", \"asasasas\", \"sasasass\"],\n",
    "        \"other_data\": [1, 2, 3, 4, 5],\n",
    "    }\n",
    ")\n",
    "gibberish = [\"asasasa\", \"sasaaasss\", \"asdasadadfa\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0c0e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    # Nearest string\n",
    "    pds.str_nearest(\"word\", word=\"banana\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50591e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(\n",
    "    # Filters to words that are similar to any word in vocab\n",
    "    pds.similar_to_vocab(\n",
    "        pl.col(\"word\"),\n",
    "        vocab=gibberish,\n",
    "        threshold=0.5,\n",
    "        metric=\"lv\",  # Levenshtein similarity. Other options: dleven, osa, jw\n",
    "        strategy=\"any\",  # True if the word is similar to any word in vocab. Other options: \"all\", \"avg\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece3794",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\n",
    "    pds.str_leven(\"word\", pl.lit(\"asasasa\"), return_sim=True).alias(\"asasasa\"),\n",
    "    pds.str_leven(\"word\", pl.lit(\"sasaaasss\"), return_sim=True).alias(\"sasaaasss\"),\n",
    "    pds.str_leven(\"word\", pl.lit(\"asdasadadfa\"), return_sim=True).alias(\"asdasadadfa\"),\n",
    "    pds.str_fuzz(\"word\", pl.lit(\"apples\")).alias(\"LCS based Fuzz match - apples\"),\n",
    "    pds.str_osa(\"word\", pl.lit(\"apples\"), return_sim=True).alias(\n",
    "        \"Optimal String Alignment - apples\"\n",
    "    ),\n",
    "    pds.str_jw(\"word\", pl.lit(\"apples\")).alias(\"Jaro-Winkler - apples\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa2a0b3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8841f2a1",
   "metadata": {},
   "source": [
    "# Stats Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6171b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df = pl.DataFrame({\"a\": [None, None] + list(np.random.normal(size=998))})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6e7445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genenrate random numbers, respecting null positions in reference column (pl.col(\"a\"))\n",
    "df.with_columns(\n",
    "    pds.random_normal(mean=0.5, std=1.0).alias(\"random_normal\"),\n",
    "    pl.when(pl.col(\"a\").is_null())\n",
    "    .then(None)\n",
    "    .otherwise(pds.random_normal(mean=0.5, std=1.0).alias(\"random_normal\"))\n",
    "    .alias(\"random_normal_that_respects_null_of_a\"),\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e13f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genenrate random string\n",
    "df.with_columns(\n",
    "    pds.random_str(min_size=1, max_size=5).alias(\"random_str\"),\n",
    "    pl.when(pl.col(\"a\").is_null())\n",
    "    .then(None)\n",
    "    .otherwise(pds.random_str(min_size=1, max_size=5))\n",
    "    .alias(\"random_str_that_respects_null_of_a\"),\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c37394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genenrate fixed size random string, while respecting column a's nulls\n",
    "df.with_columns(\n",
    "    pl.when(pl.col(\"a\").is_null())\n",
    "    .then(None)\n",
    "    .otherwise(pds.random_str(min_size=5, max_size=5))\n",
    "    .alias(\"random_str\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0c06a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.with_columns(\n",
    "    # Sample from a normal distribution, using reference column \"a\" 's mean and std\n",
    "    pds.random_normal(pl.col(\"a\").mean(), pl.col(\"a\").std()).alias(\"test1\"),\n",
    "    # Sample from uniform distribution, with low = 0 and high = \"a\"'s max, and respect the nulls in \"a\"\n",
    "    pl.when(pl.col(\"a\").is_null())\n",
    "    .then(None)\n",
    "    .otherwise(pds.random(lower=0.0, upper=pl.col(\"a\").max()).alias(\"test2\")),\n",
    ").with_columns(\n",
    "    # Add a random pertubation to test1\n",
    "    pds.perturb(\"test1\", epsilon=0.001).alias(\"test1_perturbed\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dc6583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New in v0.3.5\n",
    "# This way, we don't have a reference column, so we cannot respect nulls, but is more convenient to use.\n",
    "df.with_columns(\n",
    "    pds.random().alias(\"[0, 1)\"),\n",
    "    pds.random_normal(pl.col(\"a\").mean(), pl.col(\"a\").std()).alias(\"Normal\"),\n",
    "    pds.random_int(0, 10).alias(\"Int from [0, 10)\"),\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b63f636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genenrate 2 random sample, both normally distributed\n",
    "# Run Welch's t test on them, p value should be big since they have equal mean\n",
    "# Run a normality test. Again, p value should be big since they are normally distributed\n",
    "\n",
    "df.with_columns(\n",
    "    pds.random_normal(0.5, 1.0).alias(\"test1\"),\n",
    "    pds.random_normal(0.5, 2.0).alias(\"test2\"),\n",
    ").select(\n",
    "    pds.ttest_ind(\"test1\", \"test2\", equal_var=False).alias(\"t-test\"),\n",
    "    pds.normal_test(\"test1\").alias(\"normality_test\"),\n",
    ").select(\n",
    "    pl.col(\"t-test\").struct.field(\"statistic\").alias(\"t-tests: statistics\"),\n",
    "    pl.col(\"t-test\").struct.field(\"pvalue\").alias(\"t-tests: pvalue\"),\n",
    "    pl.col(\"normality_test\").struct.field(\"statistic\").alias(\"normality_test: statistics\"),\n",
    "    pl.col(\"normality_test\").struct.field(\"pvalue\").alias(\"normality_test: pvalue\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46a72a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 5_000\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"market_id\": range(size),\n",
    "    }\n",
    ").with_columns(\n",
    "    pl.col(\"market_id\").mod(3),\n",
    "    var1=pds.random(),\n",
    "    var2=pds.random(),\n",
    "    category_1=pds.random_int(0, 5),\n",
    "    category_2=pds.random_int(0, 10),\n",
    ")\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc4f66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In dataframe statistical tests!\n",
    "df.select(\n",
    "    pds.ttest_ind(\"var1\", \"var2\", equal_var=True).alias(\"t-test\"),\n",
    "    pds.chi2(\"category_1\", \"category_2\").alias(\"chi2-test\"),\n",
    "    pds.f_test(\"var1\", group=\"category_1\").alias(\"f-test\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dbb6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also be done in group by context\n",
    "print(\n",
    "    df.group_by(\"market_id\").agg(\n",
    "        pds.ttest_ind(\"var1\", \"var2\", equal_var=False).alias(\"t-test\"),\n",
    "        pds.chi2(\"category_1\", \"category_2\").alias(\"chi2-test\"),\n",
    "        pds.f_test(\"var1\", group=\"category_1\").alias(\"f-test\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843d54c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benford's law\n",
    "df.select(first_digit_cnt=pds.query_first_digit_cnt(pl.col(\"var1\")).explode()).with_columns(\n",
    "    # This doesn't follow benford's law because it is random data\n",
    "    first_digit_distribution=pl.col(\"first_digit_cnt\") / pl.col(\"first_digit_cnt\").sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b232e4d7",
   "metadata": {},
   "source": [
    "# Nearest Neighbors Related Tasks\n",
    "\n",
    "These queries can be very slow when data/dimension gets huge, even when processed in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aff1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars_ds as pds\n",
    "\n",
    "size = 2000\n",
    "df = pl.DataFrame(\n",
    "    {\n",
    "        \"id\": range(size),\n",
    "    }\n",
    ").with_columns(\n",
    "    pds.random().alias(\"var1\"),\n",
    "    pds.random().alias(\"var2\"),\n",
    "    pds.random().alias(\"var3\"),\n",
    "    pds.random().alias(\"r\"),\n",
    "    (pds.random() * 10).alias(\"rh\"),\n",
    "    pl.col(\"id\").cast(pl.UInt32),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fae4b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get neighbor count. The point itself is always considered a neighbor to itself.\n",
    "df.with_columns(\n",
    "    pds.query_nb_cnt(\n",
    "        pl.col(\"var1\"),\n",
    "        \"var2\",\n",
    "        \"var3\",  # Columns used as the coordinates in n-d space, str | pl.Expr\n",
    "        r=0.1,  # radius\n",
    "        dist=\"inf\",  # L Infinity distance\n",
    "        parallel=True,\n",
    "    ).alias(\"nb_l_inf_cnt\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ad83d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.with_columns(\n",
    "    pds.query_nb_cnt(\n",
    "        \"var1\",\n",
    "        \"var2\",\n",
    "        \"var3\",  # Columns used as the coordinates in n-d space, str | pl.Expr\n",
    "        r=pl.col(\"r\"),  # radius be an expression too\n",
    "        dist=\"l1\",  # L 1 distance\n",
    "        parallel=True,\n",
    "    ).alias(\"nb_l1_r_cnt\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1a2c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ids of the k nearest neighbors.\n",
    "# The point itself is always considered a neighbor to itself, so k + 1 elements will be returned.\n",
    "df.with_columns(\n",
    "    pds.query_knn_ptwise(\n",
    "        pl.col(\"var1\"),\n",
    "        pl.col(\"var2\"),\n",
    "        pl.col(\"var3\"),  # Columns used as the coordinates in n-d space\n",
    "        index=\"id\",  # pl.col(\"id\"), str | pl.Expr\n",
    "        k=3,\n",
    "        dist=\"l2\",  # squared l2\n",
    "        parallel=True,\n",
    "    ).alias(\"best friends\")\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a769f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all neighbors within radius r, call them best friends\n",
    "print(\n",
    "    df.select(\n",
    "        pl.col(\"id\"),\n",
    "        pds.query_radius_ptwise(\n",
    "            pl.col(\"var1\"),\n",
    "            pl.col(\"var2\"),\n",
    "            pl.col(\"var3\"),  # Columns used as the coordinates in 3d space\n",
    "            index=pl.col(\"id\"),\n",
    "            r=0.1,\n",
    "            dist=\"l2\",  # actually this is squared l2\n",
    "            parallel=True,\n",
    "        ).alias(\"best friends\"),\n",
    "    )\n",
    "    .with_columns(  # -1 to remove the point itself\n",
    "        (pl.col(\"best friends\").list.len() - 1).alias(\"best friends count\")\n",
    "    )\n",
    "    .head()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06cd7fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get ids of the k nearest neighbors and distances\n",
    "# The point itself is always considered a neighbor to itself, so k + 1 elements will be returned.\n",
    "df.with_columns(\n",
    "    pds.query_knn_ptwise(\n",
    "        pl.col(\"var1\"),\n",
    "        pl.col(\"var2\"),\n",
    "        pl.col(\"var3\"),  # Columns used as the coordinates in n-d space\n",
    "        index=pl.col(\"id\"),\n",
    "        k=3,\n",
    "        dist=\"l2\",  # actually this is squared l2\n",
    "        parallel=True,\n",
    "        return_dist=True,\n",
    "    ).alias(\"best_friends_w_dist\")\n",
    ").unnest(\"best_friends_w_dist\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c69ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only points near the given point\n",
    "df.filter(\n",
    "    pds.within_dist_from(\n",
    "        pl.col(\"var1\"),\n",
    "        pl.col(\"var2\"),\n",
    "        pl.col(\"var3\"),  # Columns used as the coordinates in n-d space\n",
    "        pt=[0.5, 0.5, 0.5],\n",
    "        r=0.2,\n",
    "        dist=\"l2\",  # actually this is squared l2, so this is asking for squared l2 <= 0.2\n",
    "    )\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab9e8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haversine distance is available when dimension is 2\n",
    "df.filter(\n",
    "    pds.within_dist_from(\n",
    "        pl.col(\"var1\"),\n",
    "        pl.col(\"var2\"),  # Columns used as the coordinates in n-d space\n",
    "        pt=[0.5, 0.5],\n",
    "        r=10,  # in km\n",
    "        dist=\"h\",\n",
    "    )\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f5ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.filter(\n",
    "    pds.within_dist_from(\n",
    "        pl.col(\"var1\"),\n",
    "        pl.col(\"var2\"),\n",
    "        pt=[0.5, 0.5],\n",
    "        # radius can also be an existing column in the dataframe.\n",
    "        r=pl.col(\"rh\"),\n",
    "        dist=\"h\",\n",
    "    )\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14627bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "friends = df.select(\n",
    "    pl.col(\"id\").cast(pl.UInt64),\n",
    "    pds.query_radius_ptwise(\n",
    "        # Columns used as the coordinates in n-d space\n",
    "        pl.col(\"var1\"),\n",
    "        pl.col(\"var2\"),\n",
    "        index=pl.col(\"id\"),\n",
    "        r=0.02,\n",
    "        dist=\"l2\",\n",
    "    ).alias(\"friends\"),\n",
    ").with_columns(pl.col(\"friends\").list.len().alias(\"count\"))\n",
    "friends.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aebd83c",
   "metadata": {},
   "source": [
    "# Compatibility\n",
    "\n",
    "## Using PDS Expressions On pl.Series, NumPy arrays, or pd.Series, etc.\n",
    "\n",
    "The output by default is always a Polars Series. The user gets to choose whether to turn it into NumPy, Pandas, or other data structures. \n",
    "\n",
    "## Using PDS with Narwhals\n",
    "\n",
    "Limited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a42a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import polars_ds as pds\n",
    "from polars_ds.compat import compat as pds2\n",
    "\n",
    "df = pds.frame(size=100_000).select(\n",
    "    pds.random(0.0, 1.0).round().alias(\"actual\"),\n",
    "    pds.random(0.0, 1.0).alias(\"predicted\"),\n",
    "    pds.random_int(0, 3).alias(\"0-2\"),\n",
    "    pds.random_int(0, 10).alias(\"0-9\"),\n",
    "    pds.random_str(min_size=1, max_size=2).alias(\"s1\"),\n",
    "    pds.random_str(min_size=1, max_size=2).alias(\"s2\"),\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6574a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd = df.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70830d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas Series\n",
    "pds2.jaccard_col(df_pd[\"0-2\"], df_pd[\"0-9\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471cbbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polars Series\n",
    "print(pds2.query_roc_auc(df[\"actual\"], df[\"predicted\"]))\n",
    "# NumPy\n",
    "pds2.return_numpy = True\n",
    "print(pds2.query_roc_auc(df[\"actual\"].to_numpy(), df[\"predicted\"].to_numpy()))\n",
    "pds2.return_numpy = False\n",
    "# Pandas\n",
    "print(pds2.query_roc_auc(df[\"actual\"].to_pandas(), df[\"predicted\"].to_pandas()))\n",
    "# PyArrow\n",
    "# Arrow series can be inputs, but the output cannot be converted correctly. Please let me know if you have a fix.\n",
    "# The work around is to use NumPy for Arrow\n",
    "pds2.return_numpy = True\n",
    "print(pds2.query_roc_auc(df[\"actual\"].to_arrow(), df[\"predicted\"].to_arrow()))\n",
    "# Other array-protocal compatible inputs\n",
    "# print(pds2.query_roc_auc(df[\"actual\"].to_jax(), df[\"predicted\"].to_jax()))\n",
    "\n",
    "pds2.return_numpy = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d15fc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy Arrays\n",
    "pds2.psi(\n",
    "    np.random.random(size=1000),\n",
    "    np.random.random(size=1000),\n",
    "    n_bins=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cc8f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd = df.to_pandas()\n",
    "df_pd[\"levenshtein_dist\"] = pds2.str_leven(df_pd[\"s1\"], df_pd[\"s2\"])\n",
    "df_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2aab4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you are using Narwhals, well, Narwhal expressions are not Polars expressions.\n",
    "# Using the pds2 module, you can run pds functions in map_batches, but this is limited to 1 input column.\n",
    "\n",
    "import narwhals as nw\n",
    "\n",
    "df_nw = nw.from_native(df_pd)\n",
    "df_nw.with_columns(\n",
    "    nw_levenshtein_dist=nw.col(\"s1\").map_batches(\n",
    "        lambda s: pds2.str_leven(s.to_numpy(), pl.lit(\"k9\"))\n",
    "    )\n",
    ").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc75129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
